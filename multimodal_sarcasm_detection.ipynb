{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UIT DSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original file\n",
    "input_file_path = '/APTTH36781/vimmsd-train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_sarcasm': '/APTTH36781/text_sarcasm.json',\n",
       " 'image_sarcasm': '/APTTH36781/image_sarcasm.json',\n",
       " 'multi_sarcasm': '/APTTH36781/multi_sarcasm.json',\n",
       " 'not_sarcasm': '/APTTH36781/not_sarcasm.json'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize empty dictionaries for the new files\n",
    "text_sarcasm = {}\n",
    "image_sarcasm = {}\n",
    "multi_sarcasm = {}\n",
    "not_sarcasm = {}\n",
    "\n",
    "# Open and read the original file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "    # Iterate through the dataset and distribute based on labels\n",
    "    for key, value in data.items():\n",
    "        if value['label'] == 'text-sarcasm':\n",
    "            text_sarcasm[key] = value\n",
    "        elif value['label'] == 'image-sarcasm':\n",
    "            image_sarcasm[key] = value\n",
    "        elif value['label'] == 'multi-sarcasm':\n",
    "            multi_sarcasm[key] = value\n",
    "        elif value['label'] == 'not-sarcasm':\n",
    "            not_sarcasm[key] = value\n",
    "\n",
    "# Save each label-specific data to a separate file\n",
    "output_file_paths = {\n",
    "    'text_sarcasm': '/APTTH36781/text_sarcasm.json',\n",
    "    'image_sarcasm': '/APTTH36781/image_sarcasm.json',\n",
    "    'multi_sarcasm': '/APTTH36781/multi_sarcasm.json',\n",
    "    'not_sarcasm': '/APTTH36781/not_sarcasm.json'\n",
    "}\n",
    "\n",
    "with open(output_file_paths['text_sarcasm'], 'w', encoding='utf-8') as file:\n",
    "    json.dump(text_sarcasm, file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "with open(output_file_paths['image_sarcasm'], 'w', encoding='utf-8') as file:\n",
    "    json.dump(image_sarcasm, file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "with open(output_file_paths['multi_sarcasm'], 'w', encoding='utf-8') as file:\n",
    "    json.dump(multi_sarcasm, file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "with open(output_file_paths['not_sarcasm'], 'w', encoding='utf-8') as file:\n",
    "    json.dump(not_sarcasm, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "output_file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import easyocr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được lưu thành công vào file JSON.\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn thư mục gốc chứa các ảnh\n",
    "image_directory = \"D:/APTTH36781/public_test/dev-images/\"\n",
    "\n",
    "# Hàm trích xuất văn bản từ ảnh\n",
    "def text_in_image(image_path):\n",
    "    reader = easyocr.Reader(['vi'], gpu=True)  # Khởi tạo EasyOCR với tiếng Việt\n",
    "    result = reader.readtext(image_path, detail=0)  # Trích xuất văn bản (detail=0 để chỉ lấy văn bản)\n",
    "    return result\n",
    "\n",
    "# Mở file JSON\n",
    "with open('vimmsd-public-test.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Duyệt qua từng mục trong file JSON\n",
    "for key, value in data.items():\n",
    "    image_name = value.get(\"image\")  # Lấy tên file ảnh từ mục \"image\"\n",
    "    \n",
    "    if image_name:\n",
    "        image_path = os.path.join(image_directory, image_name)  # Kết hợp đường dẫn gốc với tên file\n",
    "        \n",
    "        if os.path.exists(image_path):  # Kiểm tra nếu ảnh tồn tại\n",
    "            extracted_texts = text_in_image(image_path)  # Trích xuất văn bản từ ảnh\n",
    "            text_in_image_str = \" \".join(extracted_texts)  # Nối danh sách thành chuỗi ký tự\n",
    "            \n",
    "            # Thêm chuỗi văn bản trích xuất được vào mục \"text_in_image\"\n",
    "            data[key][\"text_in_image\"] = text_in_image_str\n",
    "        else:\n",
    "            print(f\"File not found: {image_path}\")\n",
    "\n",
    "# Ghi lại file JSON với text_in_image đã được thêm vào\n",
    "with open('output_file.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Dữ liệu đã được lưu thành công vào file JSON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được lưu thành công vào file JSON.\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn thư mục gốc chứa các ảnh\n",
    "image_directory = \"D:/APTTH36781/train-images/\"\n",
    "\n",
    "# Hàm trích xuất văn bản từ ảnh\n",
    "def text_in_image(image_path):\n",
    "    reader = easyocr.Reader(['vi'], gpu=True)  # Khởi tạo EasyOCR với tiếng Việt\n",
    "    result = reader.readtext(image_path, detail=0)  # Trích xuất văn bản (detail=0 để chỉ lấy văn bản)\n",
    "    return result\n",
    "\n",
    "# Mở file JSON\n",
    "with open('vimmsd-train.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Duyệt qua từng mục trong file JSON\n",
    "for key, value in data.items():\n",
    "    image_name = value.get(\"image\")  # Lấy tên file ảnh từ mục \"image\"\n",
    "    \n",
    "    if image_name:\n",
    "        image_path = os.path.join(image_directory, image_name)  # Kết hợp đường dẫn gốc với tên file\n",
    "        \n",
    "        if os.path.exists(image_path):  # Kiểm tra nếu ảnh tồn tại\n",
    "            extracted_texts = text_in_image(image_path)  # Trích xuất văn bản từ ảnh\n",
    "            text_in_image_str = \" \".join(extracted_texts)  # Nối danh sách thành chuỗi ký tự\n",
    "            \n",
    "            # Thêm chuỗi văn bản trích xuất được vào mục \"text_in_image\"\n",
    "            data[key][\"text_in_image\"] = text_in_image_str\n",
    "        else:\n",
    "            print(f\"File not found: {image_path}\")\n",
    "\n",
    "# Ghi lại file JSON với text_in_image đã được thêm vào\n",
    "with open('output_file_train.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Dữ liệu đã được lưu thành công vào file JSON.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PhoBert + ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng thiết bị: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Kiểm tra xem GPU có sẵn không và thiết lập thiết bị\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Sử dụng thiết bị: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/338 [00:00<?, ?it/s]d:\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|██████████| 338/338 [05:05<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7963, Accuracy: 0.6311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [04:41<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.7373, Accuracy: 0.6681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [04:45<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.7143, Accuracy: 0.6718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [04:40<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.7059, Accuracy: 0.6741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [04:47<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.6873, Accuracy: 0.6856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [05:38<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.6839, Accuracy: 0.6874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [04:38<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.6893, Accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [04:40<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.6695, Accuracy: 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [04:38<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.6661, Accuracy: 0.6913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [04:37<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.6636, Accuracy: 0.6988\n",
      "Model trained and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load PhoBERT-base for text\n",
    "phobert_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "phobert_model = AutoModel.from_pretrained(\"vinai/phobert-base\").to(device)\n",
    "\n",
    "# Load a pre-trained ResNet for image processing\n",
    "resnet_model = models.resnet50(pretrained=True).to(device)\n",
    "resnet_model.fc = nn.Identity()  # Remove the classification layer to get features\n",
    "\n",
    "# Define transformation for image preprocessing\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom dataset class\n",
    "class SarcasmDataset(Dataset):\n",
    "    def __init__(self, json_data, image_folder, transform=None):\n",
    "        # Chuyển đổi json_data thành danh sách nếu nó không phải là danh sách\n",
    "        if isinstance(json_data, dict):\n",
    "            self.data = list(json_data.values())  # Hoặc danh sách các giá trị\n",
    "        else:\n",
    "            self.data = json_data\n",
    "            \n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or idx >= len(self.data):\n",
    "            raise IndexError(\"Index out of bounds\")\n",
    "\n",
    "        item = self.data[idx]\n",
    "\n",
    "        if \"image\" not in item or \"label\" not in item or \"caption\" not in item:\n",
    "            raise KeyError(f\"Missing required fields in item at index {idx}\")\n",
    "\n",
    "        image_path = os.path.join(self.image_folder, item[\"image\"])\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            image = torch.zeros(3, 224, 224)\n",
    "\n",
    "        # Ánh xạ các chuỗi nhãn thành số nguyên\n",
    "        label_mapping = {\n",
    "            \"multi-sarcasm\": 0,\n",
    "            \"not-sarcasm\": 1,\n",
    "            \"image-sarcasm\": 2,\n",
    "            \"text-sarcasm\": 3\n",
    "        }\n",
    "\n",
    "\n",
    "        label_str = item[\"label\"]\n",
    "        if label_str not in label_mapping:\n",
    "            raise ValueError(f\"Invalid label '{label_str}' at index {idx}\")\n",
    "        label = torch.tensor(label_mapping[label_str])\n",
    "\n",
    "        caption = item[\"caption\"]\n",
    "        text_in_image = item.get(\"text_in_image\", \"\")\n",
    "\n",
    "        return image, caption, text_in_image, label\n",
    "\n",
    "\n",
    "# Custom classification head for combining text and image features\n",
    "class SarcasmClassifier(nn.Module):\n",
    "    def __init__(self, text_feature_size, image_feature_size, num_classes=4):\n",
    "        super(SarcasmClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(text_feature_size + image_feature_size, num_classes)\n",
    "\n",
    "    def forward(self, text_features, image_features):\n",
    "        combined_features = torch.cat((text_features, image_features), dim=1)\n",
    "        return self.fc(combined_features)\n",
    "\n",
    "# Load the training data\n",
    "train_json_path = r\"D:/APTTH36781/output_file_train.json\"\n",
    "train_image_folder = r\"D:/APTTH36781/train-images\"\n",
    "\n",
    "with open(train_json_path, 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = SarcasmDataset(train_data, train_image_folder, transform=image_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create the classifier model\n",
    "classifier = SarcasmClassifier(text_feature_size=768, image_feature_size=2048, num_classes=4).to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Adjust as needed\n",
    "classifier.train()  # Set model to training mode\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, captions, text_in_images, labels in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Get features for images\n",
    "        with torch.no_grad():\n",
    "            image_features = resnet_model(images)\n",
    "\n",
    "        # Process the captions\n",
    "        inputs = phobert_tokenizer(captions, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            text_features = phobert_model(**inputs).pooler_output.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = classifier(text_features, image_features)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(classifier.state_dict(), 'sarcasm_classifier.pth')\n",
    "print(\"Model trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\QuynhAnh\\AppData\\Local\\Temp\\ipykernel_20748\\3969397492.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classifier.load_state_dict(torch.load('sarcasm_classifier.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to output_predictions_test.json\n"
     ]
    }
   ],
   "source": [
    "# Tải mô hình đã huấn luyện\n",
    "classifier.load_state_dict(torch.load('sarcasm_classifier.pth'))\n",
    "classifier.eval()  # Đặt mô hình vào chế độ dự đoán\n",
    "\n",
    "# Prediction function\n",
    "def predict_sarcasm(image_path, caption, text_in_image=None):\n",
    "    # Process the image\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    image_tensor = image_transforms(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Extract image features using ResNet\n",
    "    with torch.no_grad():\n",
    "        image_features = resnet_model(image_tensor).to(device)\n",
    "\n",
    "    # Process the caption using PhoBERT\n",
    "    inputs = phobert_tokenizer(caption, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Chuyển các tensor văn bản sang thiết bị\n",
    "    with torch.no_grad():\n",
    "        text_features = phobert_model(**inputs).pooler_output.to(device)\n",
    "\n",
    "    # Check if text_in_image exists and process it similarly to caption\n",
    "    text_features_image_text = None\n",
    "    if text_in_image:\n",
    "        inputs_image_text = phobert_tokenizer(text_in_image, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        inputs_image_text = {key: value.to(device) for key, value in inputs_image_text.items()}\n",
    "        with torch.no_grad():\n",
    "            text_features_image_text = phobert_model(**inputs_image_text).pooler_output.to(device)\n",
    "\n",
    "    # Predict using the classifier\n",
    "    with torch.no_grad():\n",
    "        logits = classifier(text_features, image_features)\n",
    "        predicted_label = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "        # If there is text_in_image, also predict sarcasm for it\n",
    "        if text_features_image_text is not None:\n",
    "            logits_image_text = classifier(text_features_image_text, image_features)\n",
    "            predicted_label_image_text = torch.argmax(logits_image_text, dim=1).item()\n",
    "\n",
    "            # If both caption and text_in_image are sarcastic, return \"multi-sarcasm\"\n",
    "            if predicted_label_image_text == 3 and predicted_label == 2:\n",
    "                return 0  # \"multi-sarcasm\"\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "# Function to read JSON file, predict, and save results\n",
    "def process_json(json_path, image_folder, output_json, phase=\"dev\"):\n",
    "    # Load JSON data\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    label_mapping = {\n",
    "        0: \"multi-sarcasm\",\n",
    "        1: \"not-sarcasm\",\n",
    "        2: \"image-sarcasm\",\n",
    "        3: \"text-sarcasm\"\n",
    "    }\n",
    "\n",
    "    # Iterate through each item in the JSON\n",
    "    results = {}\n",
    "    for id, item in data.items():\n",
    "        image_name = item[\"image\"]\n",
    "        caption = item[\"caption\"]\n",
    "        label = item.get(\"label\")  # Get label if available, handle null cases\n",
    "        text_in_image = item.get(\"text_in_image\", \"\")\n",
    "\n",
    "        # Create full image path\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "        # Predict label only if label is null\n",
    "        if label is None:\n",
    "            predicted_label = predict_sarcasm(image_path, caption, text_in_image)\n",
    "            results[id] = label_mapping[predicted_label] if predicted_label is not None else \"Image not found\"\n",
    "        else:\n",
    "            results[id] = label  # Use the existing label if available\n",
    "\n",
    "    # Final output data in the specified format\n",
    "    output_data = {\n",
    "        \"results\": results,\n",
    "        \"phase\": phase\n",
    "    }\n",
    "\n",
    "    # Save results to output JSON\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "\n",
    "# Example usage\n",
    "json_input_path = \"D:\\\\APTTH36781\\\\output_file.json\"\n",
    "image_folder_path = \"D:\\\\APTTH36781\\\\public_test\\\\dev-images\"\n",
    "output_json_path = \"output_predictions_test.json\"\n",
    "\n",
    "process_json(json_input_path, image_folder_path, output_json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
